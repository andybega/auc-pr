library(separationplot)
library(ROCR)
source("~/Work/R_utilities/binary-fit.R")
separationplot(input_models[[1]], y, newplot=FALSE)
auc(y, input_models[[2]])
combined <- rowSums(do.call(cbind, input_models))
range(combined)
str(input_models)
input_coder <- function(model_no) {
x <- ifelse(y==1,
partition==model_no,  # for y=1, predict 1 if in partition
rbinom(1, 1, 0.05)
)
x <- as.numeric(x)
x
}
input_models <- lapply(1:4, input_coder)
library(separationplot)
library(ROCR)
source("~/Work/R_utilities/binary-fit.R")
separationplot(input_models[[1]], y, newplot=FALSE)
auc(y, input_models[[2]])
separationplot(input_models[[4]], y, newplot=FALSE)
partition
hist(partition)
input_coder <- function(model_no) {
x <- ifelse(y==1,
partition==model_no,  # for y=1, predict 1 if in partition
rbinom(1, 1, 0.05)
)
x <- as.numeric(x)
x
}
input_models <- lapply(1:4, input_coder)
separationplot(input_models[[4]], y, newplot=FALSE)
separationplot(input_models[[3]], y, newplot=FALSE)
separationplot(input_models[[1]], y, newplot=FALSE)
separationplot(input_models[[2]], y, newplot=FALSE)
separationplot(input_models[[3]], y, newplot=FALSE)
separationplot(input_models[[4]], y, newplot=FALSE)
(y==1)[partition==model_no]
(y==1)[partition==4]
sum((y==1)[partition==4])
sum(y)
input_coder <- function(model_no) {
y0_pred <- rbinom(1000, 1, 0.05)
x <- ifelse(y==1,
partition==model_no,  # for y=1, predict 1 if in partition
y0_pred
)
x <- as.numeric(x)
x
}
input_models <- lapply(1:4, input_coder)
library(separationplot)
library(ROCR)
source("~/Work/R_utilities/binary-fit.R")
separationplot(input_models[[4]], y, newplot=FALSE)
auc(y, input_models[[2]])
combined <- rowSums(do.call(cbind, input_models))
range(combined)
combined <- as.numeric(combined > 0)
separationplot(combined, y, newplot=FALSE)
y0_pred <- rbinom(1000, 1, 0.05)
table(y0_pred)
# For a given input model, predict 1 if y=1 and in partition for that model,
# and if y=0, predicte 1 with p=0.1 to capture some model error.
input_coder <- function(model_no) {
y0_pred <- rbinom(1000, 1, 0.1)
x <- ifelse(y==1,
partition==model_no,  # for y=1, predict 1 if in partition
y0_pred
)
x <- as.numeric(x)
x
}
input_models <- lapply(1:4, input_coder)
table(input_models[[1]], y)
library(separationplot)
library(ROCR)
source("~/Work/R_utilities/binary-fit.R")
separationplot(input_models[[4]], y, newplot=FALSE)
auc(y, input_models[[2]])
combined <- rowSums(do.call(cbind, input_models))
combined <- as.numeric(combined > 0)
separationplot(combined, y, newplot=FALSE)
separationplot(input_models[[4]], y, newplot=FALSE)
auc(y, input_models[[2]])
separationplot(combined, y, newplot=FALSE)
auc(y, combined)
# For a given input model, predict 1 if y=1 and in partition for that model,
# and if y=0, predicte 1 with p=0.05 to capture some model error.
input_coder <- function(model_no) {
y0_pred <- rbinom(1000, 1, 0.05)
x <- ifelse(y==1,
partition==model_no,  # for y=1, predict 1 if in partition
y0_pred
)
x <- as.numeric(x)
x
}
input_models <- lapply(1:4, input_coder)
library(separationplot)
library(ROCR)
source("~/Work/R_utilities/binary-fit.R")
separationplot(input_models[[4]], y, newplot=FALSE)
auc(y, input_models[[2]])
combined <- rowSums(do.call(cbind, input_models))
combined <- as.numeric(combined > 0)
separationplot(combined, y, newplot=FALSE)
auc(y, combined)
table(combined, y)
#EOI III Model delivery Duke 2/2015
#Implemented for R package wicews 0.5.*
#Authors: Michael D. Ward, Simon Weschle
#University: Duke University
# <WICEWS suite of programs to predict crisis events.>
#     Copyright Â© <2015>  <Michael D. Ward, Duke University>
#
#     This program is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This program is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     The GNU Public License is available at <http://www.gnu.org/licenses/>.
#load library and data
library(wicews)
data(crisp.data)
data(cutoffs)
#automatically set teststart date for demo
start = as.character(crisp.data$monthID[crisp.data$date==cutoffs$teststart][1])
#functions to be used
lagger<-function(variable, country, year, laglength){
country<-as.character(country)
laggedvar<-rep(NA,length(variable))
leadingNAs<-rep(NA,laglength)
countryshift<-c(leadingNAs, country[1:(length(country)-laglength)])
variableshift<-c(leadingNAs, variable[1:(length(variable)-laglength)])
replacementrefs<-country==countryshift
replacementrefs[is.na(replacementrefs)==T]<-FALSE
laggedvar[replacementrefs]<-variableshift[replacementrefs]
laggedvar
}
#some ex-post variable creation
crisp.data$egip_groups_count.bin.l1 <- ifelse(crisp.data$egip_groups_count.l1>=1,1,0)
crisp.data$excl_groups_count.bin.l1 <- ifelse(crisp.data$excl_groups_count.l1>=1,1,0)
crisp.data$log.SP.POP.TOTL.l1 <- log(crisp.data$SP.POP.TOTL.l1)
crisp.data$log.AG.LND.TOTL.K2.l1 <- log(crisp.data$AG.LND.TOTL.K2.l1)
crisp.data$ins.h.count.govt.l1 <- crisp.data$ins.h.count.both.l1 - crisp.data$ins.h.count.one.l1
crisp.data$ins.l.count.govt.l1 <- crisp.data$ins.l.count.both.l1 - crisp.data$ins.l.count.one.l1
crisp.data$log.NY.GDP.PCAP.KD.l1 <- log(crisp.data$NY.GDP.PCAP.KD.l1)
crisp.data$growth.NY.GDP.PCAP.KD <- 100*(crisp.data$NY.GDP.PCAP.KD-crisp.data$NY.GDP.PCAP.KD.l12)/crisp.data$NY.GDP.PCAP.KD.l12
crisp.data$NY.GDP.MKTP.KD.l12 <- lagger(crisp.data$NY.GDP.MKTP.KD, crisp.data$country, crisp.data$year, 12)
crisp.data$growth.NY.GDP.MKTP.KD <- 100*(crisp.data$NY.GDP.MKTP.KD-crisp.data$NY.GDP.MKTP.KD.l12)/crisp.data$NY.GDP.MKTP.KD.l12
crisp.data$SP.POP.TOTL.l12 <- lagger(crisp.data$SP.POP.TOTL, crisp.data$ccode, crisp.data$year, 12)
crisp.data$growth.SP.POP.TOTL <- 100*(crisp.data$SP.POP.TOTL-crisp.data$SP.POP.TOTL.l12)/crisp.data$SP.POP.TOTL.l12
## Themes: Names and model specifications
dpc.names <- c("Economy", "Demographics", "Politics", "Infrastructure", "Behavioral, DPC", "Behavioral, Gov and Opp", "Neighborhood Gower Econ", "Neighborhood knn4")
dpc.best <-  c(
"dpc ~ 1 + (1 | ccode) +  FP.CPI.TOTL.ZG.l1",
"dpc ~ 1 + (1 | ccode) +  growth.SP.POP.TOTL",
"dpc ~ 1 + (1 | ccode) +  DEMOC.l1 + AUTOC.l1 + State.Dept..l1",
"dpc ~ 1 + (1 | ccode) +  log.AG.LND.TOTL.K2.l1",
"dpc ~ 1 + (1 | ccode) +  dom.cris.h.count.l1 + dom.cris.hA.count.l1 + dom.cris.i.count.l1",
"dpc ~ 1 + (1 | ccode) +  intratension.l1 + repression.l1 + opp_protests.l1",
"dpc ~ 1 + (1 | ccode) +  W.gower.econ.dom.cris.h.count.l1 + W.gower.econ.dom.cris.l.count.l1",
"dpc ~ 1 + (1 | ccode) +  W.knn4.std.dom.cris.h.count.l1")
#current start date:
print(start)
# we shorten the training period to after Feb 2002 b/c annual growth variables are NA before
crisp.data.2 <- crisp.data[crisp.data$date>="2002-03-01",]
### Theme models of EOI occurence
set.seed(12345)
insampledata <- outsampledata <- NULL
for(i in 1:length(dpc.best)){
m <- icewsest.blmer(as.formula(dpc.best[i]), data=crisp.data.2, teststart=start, cutpoint=0.1)
if(i==1){
insampledata <- data.frame(m$trainingset$year, m$trainingset$month, m$trainingset$country, m$trainingset$ccode,  m$trainingset$dpc, m$in.pred)
outsampledata <- data.frame(m$testset$year, m$testset$month, m$testset$country, m$testset$ccode,  m$testset$dpc, m$out.pred)
}
if(i>1){
insampledata <- data.frame(insampledata, m$in.pred)
outsampledata <- data.frame(outsampledata, m$out.pred)
}
}
colnames(insampledata) <- colnames(outsampledata) <- c("year", "month",  "country", "ccode",  "occurrence", paste0("prediction_", 1:length(dpc.best)))
### EBMA of the themes, with wisdom of crowds parameter (0.02)
this.ForecastData <- makeForecastData(.predCalibration = insampledata[,paste0("prediction_", 1:length(dpc.best))],
.outcomeCalibration = insampledata[,"occurrence"],
.predTest = outsampledata[,paste0("prediction_", 1:length(dpc.best))],
.outcomeTest = outsampledata[,"occurrence"],
.modelNames=dpc.names)
this.ensemble <- calibrateEnsemble(this.ForecastData, model="logit", maxIter=25000, exp=3, useModelParams=TRUE, const=0.02)
insampledata <- data.frame(insampledata, this.ensemble@predCalibration[,1,1])
outsampledata <- data.frame(outsampledata,  this.ensemble@predTest[,1,1])
colnames(insampledata)[length(colnames(insampledata))] <- colnames(outsampledata)[length(colnames(outsampledata))] <- "prediction_EBMA"
##calculate performance
cutpoint <- 0.2
brier.in <- sum((insampledata$prediction_EBMA - insampledata$occurrence)^2)/length(insampledata$prediction_EBMA)
brier.out <- sum((outsampledata$prediction_EBMA - outsampledata$occurrence)^2)/length(outsampledata$prediction_EBMA)
auc.in <- somers2(insampledata$prediction_EBMA, insampledata$occurrence)[1]
auc.out <- somers2(outsampledata$prediction_EBMA, outsampledata$occurrence)[1]
precision.in <- dim(insampledata[insampledata$prediction_EBMA >= cutpoint & insampledata$occurrence == 1,])[1]/dim(insampledata[insampledata$prediction_EBMA >= cutpoint,])[1]
precision.out <- dim(outsampledata[outsampledata$prediction_EBMA >= cutpoint & outsampledata$occurrence == 1,])[1]/dim(outsampledata[outsampledata$prediction_EBMA >= cutpoint,])[1]
recall.in <- dim(insampledata[insampledata$prediction_EBMA >= cutpoint & insampledata$occurrence == 1,])[1]/dim(insampledata[insampledata$occurrence == 1,])[1]
recall.out <- dim(outsampledata[outsampledata$prediction_EBMA >= cutpoint & outsampledata$occurrence == 1,])[1]/dim(outsampledata[outsampledata$occurrence == 1,])[1]
accuracy.in <- ( dim(insampledata[insampledata$prediction_EBMA >= cutpoint & insampledata$occurrence == 1,])[1] + dim(insampledata[insampledata$prediction_EBMA < cutpoint & insampledata$occurrence == 0,])[1] )/ dim(insampledata)[1]
accuracy.out <- ( dim(outsampledata[outsampledata$prediction_EBMA >= cutpoint & outsampledata$occurrence == 1,])[1] + dim(outsampledata[outsampledata$prediction_EBMA < cutpoint & outsampledata$occurrence == 0,])[1] )/ dim(outsampledata)[1]
brier.in
brier.out
auc.in
auc.out
precision.in
precision.out
recall.in
recall.out
accuracy.in
accuracy.out
### create the predictions
predict.data.2 <- crisp.data.2[crisp.data.2$date==cutoffs$dataend,]
hphat <- outsampledata$prediction_EBMA
month.1<-hphat
month.2<-1-(1-hphat)^2
month.3<-1-(1-hphat)^3
month.4<-1-(1-hphat)^4
month.5<-1-(1-hphat)^5
month.6<-1-(1-hphat)^6
predict.table.ensemble <- data.frame(ccode=predict.data.2$ccode, month.1, month.2,month.3,month.4,month.5,month.6)
insample.table.ensemble <- data.frame(ccode=insampledata$ccode,
year=insampledata$year,
month=insampledata$month,
pred=insampledata$prediction_EBMA)
outsample.table.ensemble <- data.frame(ccode=outsampledata$ccode,
year=outsampledata$year,
month=outsampledata$month,
pred=outsampledata$prediction_EBMA)
##############
#PLEASE TYPE
#write.csv(predict.table.ensemble, file="YOURPATH/predict.table.ensemble.csv")
#write.csv(outsample.table.ensemble, file="YOURPATH/outsample.table.ensemble.csv")
#write.csv(insample.table.ensemble, file="YOURPATH/insample.table.ensemble.csv")
#TO WRITE .csv file
##############
library(dplyr)
preds <- insampledata %>%
select(c(grep("prediction_", colnames(insampledata))), "occurrence")
preds <- insampledata %>%
select(c(grep("prediction_|occurrence", colnames(insampledata))))
head(preds)
preds <- insampledata %>%
select(c(grep("prediction_[0-9]|occurrence", colnames(insampledata))))
head(preds)
preds <- insampledata %>%
select(c(grep("prediction_[0-9]|occurrence", colnames(insampledata)))) %>%
arrange(occurrence)
head(preds)
tail(preds)
preds <- insampledata %>%
select(c(grep("prediction_[0-9]|occurrence", colnames(insampledata)))) %>%
arrange(occurrence, prediction_1) %>%
select(-"occurrence")
preds <- insampledata %>%
select(c(grep("prediction_[0-9]|occurrence", colnames(insampledata)))) %>%
arrange(occurrence, prediction_1) %>%
select(-occurrence)
head(preds)
preds <- insampledata %>%
select(c(grep("prediction_[0-9]|occurrence", colnames(insampledata)))) %>%
arrange(occurrence, prediction_1)
inputs <- preds %>% select(-occurrence)
seq_len(nrow(inputs))
inputs <- preds %>% select(-occurrence) %>%
mutate(x = seq_len(n()))
inputs <- melt(inputs, id.vars="x")
library(reshape2)
inputs <- melt(inputs, id.vars="x")
head(inputs)
p <- ggplot(data=inputs, aes(x=x, y=variable)) +
geom_tile(aes(fill=value)) +
scale_fill_gradient(limits=c(0, 1), low="yellow", high="blue", name="Pr(y=1)") +
scale_y_discrete(name="Input model") +
scale_x_continuous(name="", breaks=NULL) +
annotate("segment", x=match(1, preds$occurrence), xend=match(1, preds$y), y=0.5, yend=4.5, col="white", lwd=1) +
annotate("text", x=match(1, preds$occurrence)-70, y=0.75, label="y=0", col="white", size=5) +
annotate("text", x=match(1, preds$occurrence)+70, y=0.75, label="y=1", col="white", size=5)
p
library(ggplot2)
p <- ggplot(data=inputs, aes(x=x, y=variable)) +
geom_tile(aes(fill=value)) +
scale_fill_gradient(limits=c(0, 1), low="yellow", high="blue", name="Pr(y=1)") +
scale_y_discrete(name="Input model") +
scale_x_continuous(name="", breaks=NULL) +
annotate("segment", x=match(1, preds$occurrence), xend=match(1, preds$y), y=0.5, yend=4.5, col="white", lwd=1) +
annotate("text", x=match(1, preds$occurrence)-70, y=0.75, label="y=0", col="white", size=5) +
annotate("text", x=match(1, preds$occurrence)+70, y=0.75, label="y=1", col="white", size=5)
p
cor(inputs[, 1], inputs[, 2])
cor(preds[, 2], preds[, 3])
cor(preds[, -1])
plot(cor(preds[, -1]))
qplot(x=Var1, y=Var2, data=melt(cor(preds[, -1], use="p")), fill=value, geom="tile") +
scale_fill_gradient2(limits=c(-1, 1))
nrow(inputs)
nrow(preds$occurrrence==1)
sum(preds$occurrrence==1)
head(preds)
table(preds$occurrrence==1)
table(preds$occurrence==1)
(sum(preds$occurrence==1)/2)
preds <- insampledata %>%
select(c(grep("prediction_[0-9]|occurrence", colnames(insampledata)))) %>%
arrange(occurrence, prediction_1)
head(preds)
colnames(preds) <- c("y", dpc.names)
head(preds)
inputs <- preds %>% select(-y) %>%
mutate(x = seq_len(n()))
inputs <- melt(inputs, id.vars="x")
head(inputs)
p1
library(ggplot2)
library(scales)
# Simulate binary data and predictions given wanted class imbalance and AUC.
#
#   This is accomplished by mapping a vector of initial predictions to an
#   outcome y so that p_{i+} and
#
# The predictions for a given imbalance level are comparable accross specified
# AUC, i.e. they have the same distribution, just the mapping to outcomes is
# different.
#
# Probalistic, so different runs will give different results, especially for
# very imbalanced data.
#
sim_model <- function(pos_neg, a, n, shuffle=100, plot=FALSE) {
# Outcome
y <- rbinom(n, 1, pos_neg)
# Create predictions:
# Raw predictions are logistic distribution shifted so that `a` fraction
# of density is above 0
p <- plogis(rlogis(n, qlogis(pos_neg, lower.tail=FALSE), 1))
# We will compare all positives to a sample of negatives, and reassign
# probabilities with p = desired AUC (a)
#
# (Assumes n+ > n-, won't work otherwise)
idx_pos <- which(y==1)
# Not sure how to explain this part, result of trial and error
a <- qbeta(a, shape1=0.58, shape2=0.58)
# Initialize results; for checking
res <- data.frame(n=vector("integer", 20), auc_roc=vector("numeric", 20))
# Since n+ > n-, we need several iterations to shuffle probabilities around
for (n in 1:shuffle) {
# Sample p_{y=0} for pair comparison
idx_neg <- sample(which(y==0), sum(y))
prob <- runif(length(idx_pos))
# For each +/- pair, flip with probability `a`
for (i in 1:length(idx_pos)) {
if (p[idx_pos[i]] < p[idx_neg[i]] & prob[i] < a) {
temp <- p[idx_pos[i]]
p[idx_pos[i]] <- p[idx_neg[i]]
p[idx_neg[i]] <- temp
}
if (p[idx_pos[i]] > p[idx_neg[i]] & prob[i] > a) {
temp <- p[idx_pos[i]]
p[idx_pos[i]] <- p[idx_neg[i]]
p[idx_neg[i]] <- temp
}
}
res[n, 1] <- n
res[n, 2] <- auc_roc(y, p)
}
if (plot) {
print(qplot(data=res, x=n, y=auc_roc, ylim=c(0.5, 1)))
}
mod <- data.frame(y, p)
return(mod)
#return(res)
}
library(ROCR)
library(caTools)
#' Area under the ROC curve
#'
#' improt ROCR
auc_roc <- function(obs, pred) {
pred <- prediction(pred, obs)
auc  <- performance(pred, "auc")@y.values[[1]]
return(auc)
}
#' Area under Precision-recall curve
#'
#' import ROCR
#' import caTools
auc_pr <- function(obs, pred) {
xx.df <- prediction(pred, obs)
perf  <- performance(xx.df, "prec", "rec")
xy    <- data.frame(recall=perf@x.values[[1]], precision=perf@y.values[[1]])
# take out division by 0 for lowest threshold
xy <- subset(xy, !is.nan(xy$precision))
res   <- trapz(xy$recall, xy$precision)
res
}
# Beta beta; wtf
foo <- data.frame(a=seq(0.5, 1, by=0.01), ar=vector("numeric", 51))
for (a in seq(0.5, 1, by=0.01)) {
res <- sim_model(0.4, a, 1000, shuffle=50)
foo[foo$a==a, 2] <- mean(res[25:50, 2])
}
qplot(foo$a, foo$ar) +
stat_function(fun=pbeta, args=list(shape1=0.57, shape2=0.57))
mod1 <- sim_model(0.4, 0.6, 100, shuffle=50, plot=TRUE)
separationplot(mod1$p, mod1$y, newplot=FALSE)
mod1xy <- rocdf(p, y, mod1, "roc")
separationplot(mod1$p, mod1$y, newplot=FALSE)
# Run simulation ----------------------------------------------------------
set.seed(1235)
bal <- c(0.4, 0.1, 0.01)
auc_want <- c(0.8, 0.9, 0.95)
n_sims = 5000
for (b in seq_along(bal)) {
for (a in seq_along(auc_want)) {
cat(paste0("Balance ", bal[b], "  AUC ", auc_want[a], "\n"))
sim_name <- paste0("s", 10*b + a)
assign(sim_name, sim_model(pos_neg=bal[b], a=auc_want[a], n=n_sims, shuffle=50))
}
}
# Plot results ------------------------------------------------------------
# For a vector of observed and predicted, creates x-y coordinates for a ROC
# or PR curve.
rocdf <- function(pred, obs, data=NULL, type=NULL) {
# plot_type is "roc" or "rp"
if (!is.null(data)) {
pred <- eval(substitute(pred), envir=data)
obs  <- eval(substitute(obs), envir=data)
}
rocr_xy <- switch(type, roc=c("tpr", "fpr"), pr=c("prec", "rec"))
rocr_df <- prediction(pred, obs)
rocr_pr <- performance(rocr_df, rocr_xy[1], rocr_xy[2])
xy <- data.frame(rocr_pr@x.values[[1]], rocr_pr@y.values[[1]])
colnames(xy) <- switch(type, roc=c("tpr", "fpr"), pr=c("rec", "prec"))
return(xy)
}
# Combine xy coords for simulation ROC curves
roc_xy <- data.frame(NULL)
for (sim in ls()[grep("s[0-9]", ls())]) {
sim_res <- get(sim)
xy <- cbind(data.frame(
balance = bal[as.numeric(substr(sim, 2, 2))],
auc_roc = auc_want[as.numeric(substr(sim, 3, 3))]),
rocdf(p, y, sim_res, type="roc")
)
roc_xy <- rbind(roc_xy, xy)
}
rm(sim_res, xy)
roc_xy$balance <- factor(roc_xy$balance, levels=rev(sort(bal)))
roc_xy$auc_roc <- factor(roc_xy$auc_roc, levels=rev(sort(auc_want)))
p1 <- ggplot(data=roc_xy, aes(x=tpr, y=fpr, color=factor(auc_roc))) +
facet_wrap(~ balance) +
scale_x_continuous(expand = c(0.01, 0.01)) +
scale_y_continuous(expand = c(0.01, 0.01)) +
geom_line(show_guide=TRUE, alpha=0.7) +
geom_abline(slope=1, color="gray", alpha=0.5) +
labs(x="FPR", y="TPR") +
theme_bw()
p1
ggsave(filename="graphics/roc.png", plot=p1, width=6.4, height=2, units="in",
dpi=400, scale=1.5)
# Combine xy coords for simulation ROC curves
pr_xy <- data.frame(NULL)
for (sim in ls()[grep("s[0-9]", ls())]) {
sim_res <- get(sim)
xy <- cbind(data.frame(
balance = bal[as.numeric(substr(sim, 2, 2))],
auc_roc = auc_want[as.numeric(substr(sim, 3, 3))]),
rocdf(p, y, sim_res, type="pr")
)
pr_xy <- rbind(pr_xy, xy)
}
rm(sim_res, xy)
pr_xy$balance <- factor(pr_xy$balance, levels=rev(sort(bal)))
pr_xy$auc_roc <- factor(pr_xy$auc_roc, levels=rev(sort(auc_want)))
p2 <- ggplot(data=pr_xy, aes(x=rec, y=prec, col=auc_roc)) +
facet_wrap(~ balance) +
geom_line(show_guide=TRUE, alpha=0.7) +
labs(x="Recall", y="Precision") +
theme_bw() +
scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x, n=4),
labels = trans_format("log10", math_format(10^.x))) +
annotation_logticks(sides="l")
p2
ggsave(filename="graphics/rpc.png", plot=p2, width=6.4, height=2, units="in",
dpi=400, scale=1.5)
getwd()
setwd("~/Work/auc-pr")
ggsave(filename="graphics/rpc.png", plot=p2, width=6.4, height=2, units="in",
dpi=400, scale=1.5)
ggsave(filename="graphics/roc.png", plot=p1, width=6.4, height=2, units="in",
dpi=400, scale=1.5)
head(s11)
separationplot(s11$y, s11$p)
library(separationplot)
separationplot(s11$y, s11$p)
separationplot(s11$p, s11$y)
separationplot(s11$p, s11$y, newplot=FALSE)
dev.off()
separationplot(s11$p, s11$y, newplot=FALSE)
?separationplot
separationplot(s11$p, s11$y, newplot=FALSE, heading=paste0("11"))
